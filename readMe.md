# üîà Classificador de √Åudio - Uma aplica√ß√£o te√≥rica de Sinais e Sistemas Lineares com Ci√™ncia de Dados

## üìñ Descri√ß√£o Geral

Este projeto tem como objetivo criar um sistema de classifica√ß√£o autom√°tica de sons usando grava√ß√µes de √°udio. A base de dados utilizada √© o **ESC-50**, que re√∫ne amostras sonoras de diversas categorias, como sons de animais, alarmes, instrumentos e ambientes.

Para as 11 categorias escolhidas, foi aplicada a t√©cnica de **data augmentation** (aumento de dados), gerando varia√ß√µes artificiais dos √°udios originais e ampliando a quantidade de exemplos dispon√≠veis para o treinamento. Em seguida, s√£o extra√≠das **63 features** (caracter√≠sticas) de cada amostra, como MFCCs, centroides espectrais, contraste, entre outras.

Essas caracter√≠sticas alimentam um modelo de rede neural treinado para reconhecer os padr√µes sonoros. O sistema √© integrado a uma interface gr√°fica intuitiva, que permite gravar √°udio ao vivo e exibir, de forma pr√°tica, a classe sonora prevista com base no modelo treinado.


## ‚öô Requisitos

O projeto foi desenvolvido em **Python 3.12.7** e depende das seguintes bibliotecas:

- `numpy`
- `pandas`
- `librosa`
- `scikit-learn`
- `sounddevice`
- `matplotlib`
- `joblib`
- `streamlit`
- `tensorflow`
- `tqdm`
- `seaborn`

Todas as depend√™ncias podem ser instaladas com o seguinte comando:

```bash
pip install -r requirements.txt
```

N√£o h√° requisitos espec√≠ficos de hardware e pode ser executado em qualquer m√°quina com suporte para Python e as bibliotecas acima.

## üèó Estrutura do c√≥digo

De forma geral o projeto est√° centrado em 5 arquivos .py, sendo 4 de configura√ß√£o (**selecionarclasses.py**, **dataaugmentation.py**, **features.py** e **classificador.py**) e 1 de execu√ß√£o do app (**app.py**). 

###### esc50.csv (.\ESC-50-master\meta\esc50.csv)

Esse arquivo csv cont√©m, dentre outras features, as informa√ß√µes de classe e nome do arquivo de √°udio em quest√£o. √â ele quem torna poss√≠vel a navega√ß√£o pelos arquivos de √°udio. Cada √°udio tem 5 segundos de dura√ß√£o.

###### Arquivo 1 - selecionarclasses.py
Esse arquivo √© o ponto de partida do projeto, nele, est√° o script respons√°vel por filtrar as classes e arquivos de √°udio selecionadas para o processo de treinamento do modelo.

As classes s√£o selecionadas a partir de um vetor de strings contendo o nome de cada uma, e depois, um filtro √© aplicado no arquivo esc50.csv para que apenas os arquivos correspondentes possam ser acessados.

As classes selecionadas s√£o divididas em 3 grupos:
**Animais: Cachorro, gato e sapo.
Sons humanos: choro de beb√™, palmas e tosse.
sons cotidianos: batida na porta, teclado, sirene, alarme e sino.**

Esses ser√£o os sons que o app ser√° capaz de reconhecer.

```bash
# Classes
CLASSES_USADAS = [
    'dog', 'cat', 'frog',
    'crying_baby', 'clapping', 'coughing',
    'door_wood_knock', 'keyboard_typing', 'siren', 'clock_alarm', 'church_bells'
]

df = pd.read_csv(CSV_PATH)

# Filtro
df_filtrado = df[df['category'].isin(CLASSES_USADAS)]
print("Total por classe:")
print(df_filtrado['category'].value_counts())
```

Esse filtro tem como sa√≠da um novo arquvio csv **(.\data\esc50_filtrado.csv)** de mesma estrutura que o anterior. 

Al√©m disso, √© mostrado no terminal a quantidade de arquivos de √°udio por classe, totalizando 40 arquivos por classe, totalizando 440 arquivos de entrada inicial.
<p align="center">
  <img src="imgs\classes.png" alt="Arquivos por classe" width="200">
</p>
 
###### Arquivo 2 - dataaugmentation.py
Foi constatado que, com apenas os 440 arquivos de √°udio originais o treinamento n√£o tinha dados o suficiente para ter uma boa efic√°cia nas classifica√ß√µes.
Para resolver isso, foi necess√°rio aplicar efeitos como: **ru√≠do**, **esticar audio**, **altera√ß√£o de tom**, **varia√ß√£o de volume**, **echo** e **invers√£o** aos arquivos originais para que novas varia√ß√µes de cada um sejam criadas.

As fun√ß√µes que descrevem a aplica√ß√£o desses efeitos podem ser vistas abaixo:
```bash
# Fun√ß√µes de aumento de dados
def aplicar_ruido(y, intensidade=0.002):
    ruido = np.random.randn(len(y))
    return y + intensidade * ruido

def esticar_audio(y, taxa):
    return librosa.effects.time_stretch(y, rate=taxa)

def alterar_tom(y, sr, passos):
    return librosa.effects.pitch_shift(y, sr=sr, n_steps=passos)

def alterar_volume(y, ganho_db):
    return y * (10 ** (ganho_db / 20))

def adicionar_echo(y, sr, atraso=0.1, decaimento=0.3):
    atraso_amostras = int(sr * atraso)
    eco = np.zeros(len(y) + atraso_amostras)
    eco[:len(y)] = y
    eco[atraso_amostras:] += decaimento * y
    eco = eco / np.max(np.abs(eco)) 
    return eco.astype(y.dtype)

def inverter_audio(y):
    return y[::-1]
```
A aplica√ß√£o desses efeitos para cada √°udio √© feita de forma rand√¥mica, com cada √°udio tendo 30% de chance de ter  **ru√≠do**, **esticar audio**, **altera√ß√£o de tom** e **varia√ß√£o de volume** e 20% de chance de ter **echo** e **invers√£o** aplicados.
√â importante que seja feito dessa forma rand√¥mica, pois, a cada execu√ß√£o, os novos √°udios gerados com os efeitos aplicados s√£o diferentes. Isso previne um superajuste nos dados e o enviesamento do modelo.

```bash
        # Ru√≠do (30%)
        if random.random() < 0.3:
            y_ruido = aplicar_ruido(y, intensidade=random.uniform(0.001, 0.003))
            nome_ruido = f"noise_{nome_arquivo}"
            sf.write(os.path.join(dir_audios_aumentados, nome_ruido), y_ruido, sr)
            linhas_novas.append({**linha, 'filename': nome_ruido})

        # Altera√ß√£o de tom (30%)
        if random.random() < 0.3:
            passos = random.choice([-1, 1])
            y_tom = alterar_tom(y, sr, passos=passos)
            y_tom = normalizar_audio(y_tom)
            nome_tom = f"pitch_{nome_arquivo}"
            sf.write(os.path.join(dir_audios_aumentados, nome_tom), y_tom, sr)
            linhas_novas.append({**linha, 'filename': nome_tom})

        # Esticar √°udio (30%)
        if random.random() < 0.3:
            taxa = random.choice([0.95, 1.05])
            y_estico = esticar_audio(y, taxa=taxa)
            y_estico = normalizar_audio(y_estico)
            nome_estico = f"stretch_{nome_arquivo}"
            sf.write(os.path.join(dir_audios_aumentados, nome_estico), y_estico, sr)
            linhas_novas.append({**linha, 'filename': nome_estico})

        # Alterar volume (30%)
        if random.random() < 0.3:
            ganho = random.uniform(-3, 3)
            y_volume = alterar_volume(y, ganho)
            y_volume = normalizar_audio(y_volume)
            nome_volume = f"gain_{nome_arquivo}"
            sf.write(os.path.join(dir_audios_aumentados, nome_volume), y_volume, sr)
            linhas_novas.append({**linha, 'filename': nome_volume})

        # Echo (20%)
        if random.random() < 0.2:
            y_eco = adicionar_echo(y, sr, atraso=0.1, decaimento=0.3)
            nome_eco = f"echo_{nome_arquivo}"
            sf.write(os.path.join(dir_audios_aumentados, nome_eco), y_eco, sr)
            linhas_novas.append({**linha, 'filename': nome_eco})

        # Inverter (20%)
        if random.random() < 0.2:
            y_invertido = inverter_audio(y)
            nome_invertido = f"reverse_{nome_arquivo}"
            sf.write(os.path.join(dir_audios_aumentados, nome_invertido), y_invertido, sr)
            linhas_novas.append({**linha, 'filename': nome_invertido})
```

Ap√≥s esse processo, o n√∫mero de arquivos salta de **400** para **1176**, trazendo mais robusutez √† massa de dados e, consequentemente, mais qualidade ao treinamento do modelo.
Como sa√≠da, esse processo retorna um novo arquivo csv **(.\data\esc50_aumentado.csv)** com os mesmos moldes dos anteriores, por√©m, contendo agora tamb√©m os arquivos gerados com efeitos aplicados.